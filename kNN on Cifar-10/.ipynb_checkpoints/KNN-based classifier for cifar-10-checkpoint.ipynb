{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading raw data into python dictonary\n",
    "def loadDataset(path):\n",
    "    label_names = None\n",
    "    train_data = None \n",
    "    train_labels = None\n",
    "    test_data = None\n",
    "    test_labels = None\n",
    "    dataDict = {}\n",
    "    \n",
    "    # Creating cifar-10 files list\n",
    "    fileList = os.listdir(path)\n",
    "    \n",
    "    # extracting label_names\n",
    "    with open(path+fileList[0], 'rb') as fo:\n",
    "        dict = pickle.load(fo)\n",
    "        label_names = dict['label_names']\n",
    "        \n",
    "    \n",
    "    # extracting training_data, labels in numpy ndarrays\n",
    "    for file in fileList[1:6]:\n",
    "        with open(path+file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "            if train_data is None:\n",
    "                train_data = dict[b'data']\n",
    "            else:\n",
    "                train_data = np.concatenate((train_data, dict[b'data']))\n",
    "            if train_labels is None:\n",
    "                train_labels = dict[b'labels']\n",
    "            else:\n",
    "                train_labels = np.concatenate((train_labels, dict[b'labels']))\n",
    "    \n",
    "    # extracting test_data, labels in numpy ndarrays\n",
    "    with open(path+fileList[7], 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "        test_data = dict[b'data']\n",
    "        test_lables = dict[b'labels']\n",
    "        \n",
    "    #creating dictonary of dataset\n",
    "    dataDict['label_names'] = label_names\n",
    "    dataDict['train_data'] = train_data\n",
    "    dataDict['train_labels'] = train_labels\n",
    "    dataDict['test_data'] = test_data\n",
    "    dataDict['test_labels'] = test_lables\n",
    "    \n",
    "    return dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "dataset = loadDataset('./cifar-10-batches-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 10 random unique test data\n",
    "def genTestData():\n",
    "    test_labels = dataset['test_labels']\n",
    "    dataInd = []\n",
    "    data = set()\n",
    "    i = np.random.randint(500)\n",
    "    while len(data) != 10:\n",
    "        if(test_labels[i] not in data):\n",
    "            dataInd.append(i)\n",
    "            data.add(test_labels[i])\n",
    "        i+=1\n",
    "    return dataInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating k-Nearest Neighbors\n",
    "class KNN:\n",
    "    def train(self, train_data):\n",
    "        self.train_data = train_data\n",
    "    def predict(self, test_data):\n",
    "        predict_data = []\n",
    "        for i,data in enumerate(self.train_data):\n",
    "            predict_data.append([distance.euclidean(data, test_data), i])\n",
    "        return sorted(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.train(dataset['train_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(data):\n",
    "    img = data\n",
    "    R = img[:1024].reshape(32, 32)\n",
    "    G = img[1024:2048].reshape(32, 32)\n",
    "    B = img[2048:].reshape(32, 32)\n",
    "    return np.dstack((R, G, B))\n",
    "\n",
    "def showPredictImage(data):\n",
    "    fig,ax = plt.subplots(1, 5, figsize=(6, 6))\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        axi.imshow(getImage(data[i][0]), cmap='binary')\n",
    "        axi.set(xticks=[], yticks=[])\n",
    "        axi.set_title(dataset['label_names'][data[i][1]])\n",
    "        # print(dataset['train_labels'][data[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 10 random unique test data\n",
    "td = genTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in td:\n",
    "    predict_data = knn.predict(dataset['test_data'][t])[:10]\n",
    "    data = []\n",
    "    for pd in predict_data:\n",
    "        data.append((dataset['train_data'][pd[1]], dataset['train_labels'][pd[1]]))\n",
    "    showPredictImage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
